import { NextResponse } from 'next/server';
import OpenAI from 'openai';

import { checkCoreSessionLimit, extractRBACContext, incrementGuestSessionUsage } from '@/src/lib/rbac-enforcer';

const OPENAI_API_KEY = process.env.OPENAI_API_KEY;
if (!OPENAI_API_KEY) {
  throw new Error('Missing OPENAI_API_KEY');
}

const openai = new OpenAI({
  apiKey: OPENAI_API_KEY,
  timeout: 20000, // 20s timeout for structuring
});

// Add a timeout wrapper for promises
function withTimeout<T>(promise: Promise<T>, timeoutMs: number, errorMessage: string): Promise<T> {
  return Promise.race([
    promise,
    new Promise<T>((_, reject) =>
      setTimeout(() => reject(new Error(errorMessage)), timeoutMs),
    ),
  ]);
}

// System prompt for consultation content structuring
function generateStructuringPrompt(): string {
  return `You are a clinical documentation assistant. Your task is to extract and clean clinical content from two input sources:

TRANSCRIPT:
A noisy, unstructured transcript from ambient speech.
This may contain irrelevant chatter, repeated words, and unclear phrasing.

ADDITIONAL CLINICAL DATA:
Notes typed by the GP during or after the consultation.
This is typically more accurate and should be treated as the most reliable source.

The goal is to organise the transcript into discrete logical blocks so downstream systems can generate templated clinical notes more easily.

# üîç Instructions

## 1. Think step-by-step before writing output:
* First, identify the distinct clinical or administrative topics discussed (e.g. ‚Äúheadache‚Äù, ‚Äúeczema‚Äù, ‚Äúrepeat prescription‚Äù).
* Then, extract relevant facts or observations stated about each problem ‚Äî **only if they were mentioned explicitly or clearly implied**.
* Group all content about the same problem together ‚Äî **avoid splitting symptoms from the same issue** (e.g. ‚Äúheadache with nasal congestion‚Äù is a single URI problem, not two).
* If topics are discussed in a disorganised way, restructure them into clean blocks while preserving all original meaning. Keep sentences together if they logically relate to the same issue.
* Capture all other information (e.g. advice, prescriptions, general discussion) as separate blocks **only if clearly discussed**.

## 2. Factual constraint:

* Never fabricate, infer, or summarise.
* If something is unclear, include it **exactly as spoken**.
* Do not hallucinate or add typical advice (e.g. ‚Äústay hydrated‚Äù, ‚Äúfollow-up in 1 week‚Äù) unless **explicitly mentioned** in the transcript.
* **All information in the transcript must appear somewhere in your output** ‚Äî do not omit clinically relevant statements.

## 3. Ambiguity handling:

* If details are vague or brief (e.g. just the word ‚Äúfever‚Äù), simply record that word ‚Äî **do not expand on it or invent details**.
* Flag ambiguous or unclear statements using (unclear) or (ambiguous) where needed.

## 4. Formatting rules:

* Do **not** use any headings, bullet points, or section labels.
* Separate each clinical issue or logical block with a **blank line**.
* Maintain the full original meaning, but clean up grammar and structure for readability.
* **DO NOT guess what the GP probably meant** ‚Äî only use what was clearly said.

## 5. Output constraint:

* Your output **must not be significantly longer than the input transcript**.
* If the input is short, the output should remain minimal and strictly factual.

---

## ‚úÖ Output Format Example (for format only)

Patient reports ongoing headaches for the past 2 weeks. The pain is mostly behind the eyes and worsens in the afternoon. No visual disturbances or nausea reported.

Asked about sleep ‚Äî says it's been disrupted but unsure if related.

Requesting another script for cetirizine, says it helps with nasal congestion. No other medications discussed.

`;
}

// Structure consultation content using AI
async function structureTranscript(rawContent: string): Promise<string> {
  if (!rawContent || rawContent.trim() === '') {
    throw new Error('Empty content provided');
  }

  const systemPrompt = generateStructuringPrompt();

  const completion = await openai.chat.completions.create({
    model: 'gpt-4o-mini',
    messages: [
      { role: 'system', content: systemPrompt },
      { role: 'user', content: `Please organise this consultation content:\n\n${rawContent}` },
    ],
    temperature: 0.1, // Low temperature for consistent structuring
    max_tokens: 2000, // Generous limit for structured output
  });

  const structuredContent = completion.choices[0]?.message?.content;
  if (!structuredContent) {
    throw new Error('No structured content generated');
  }

  return structuredContent.trim();
}

// Structure consultation transcript
export async function POST(req: Request) {
  const startTime = Date.now();
  let contentToStructure = ''; // Declare here so it's available in catch block

  try {
    // Parse request body early with timeout
    const body = await withTimeout(
      req.json(),
      5000,
      'Request parsing timeout',
    );

    const { transcription: rawContent, guestToken: bodyGuestToken, previewMode = false } = body;
    contentToStructure = rawContent; // Store for fallback use

    // Quick validation first
    if (!contentToStructure || contentToStructure.trim() === '') {
      return NextResponse.json({
        code: 'BAD_REQUEST',
        message: 'Missing or empty content to structure',
      }, { status: 400 });
    }

    // Extract RBAC context and check permissions
    const context = await withTimeout(
      extractRBACContext(req).then((ctx) => {
        // Override guest token from request body if not found in headers
        if (!ctx.guestToken && bodyGuestToken) {
          return { ...ctx, guestToken: bodyGuestToken };
        }
        return ctx;
      }),
      5000,
      'Authentication timeout',
    );

    // Check permissions (same as consultation/notes)
    const permissionCheck = await withTimeout(
      checkCoreSessionLimit(context),
      5000,
      'Permission check timeout',
    );

    if (!permissionCheck.allowed) {
      return new Response(
        JSON.stringify({
          error: permissionCheck.reason || 'Access denied',
          message: permissionCheck.upgradePrompt || 'Insufficient permissions',
          remaining: permissionCheck.remaining,
          resetTime: permissionCheck.resetTime?.toISOString(),
        }),
        {
          status: permissionCheck.reason?.includes('limit') ? 429 : 403,
          headers: { 'Content-Type': 'application/json' },
        },
      );
    }

    // Use guestToken from updated context
    const guestToken = context.guestToken;

    // Start session tracking in background (don't await to prevent delays)
    if (guestToken) {
      incrementGuestSessionUsage(guestToken, `Content structuring ${new Date().toLocaleString()}`, 'structure-transcript')
        .catch(error => console.error('Failed to increment guest session usage:', error));
    }

    // Check remaining time before starting OpenAI call
    const elapsedTime = Date.now() - startTime;
    const remainingTime = 20000 - elapsedTime; // 20s total budget for structuring

    if (remainingTime < 5000) {
      return NextResponse.json({
        code: 'TIMEOUT_ERROR',
        message: 'Request processing took too long. Please try again.',
        fallbackTranscript: contentToStructure, // Provide fallback
      }, { status: 408 });
    }

    // Structure the content with dynamic timeout
    const structuringTimeout = Math.min(remainingTime - 2000, 15000); // Max 15s for AI call
    const structuredTranscript = await withTimeout(
      structureTranscript(contentToStructure),
      structuringTimeout,
      'Content structuring timeout',
    );

    // Check if admin user has requested preview mode
    const isAdminPreviewMode = context.tier === 'admin' && previewMode;

    if (isAdminPreviewMode) {
      // Return structured content for admin preview/editing
      return NextResponse.json({
        structuredTranscript,
        requiresReview: true,
        isPreviewMode: true,
        originalTranscript: contentToStructure,
        originalLength: contentToStructure.length,
        structuredLength: structuredTranscript.length,
        processingTimeMs: Date.now() - startTime,
        userTier: context.tier,
      });
    }

    // Standard response for non-preview mode
    return NextResponse.json({
      structuredTranscript,
      originalLength: contentToStructure.length,
      structuredLength: structuredTranscript.length,
      processingTimeMs: Date.now() - startTime,
    });
  } catch (error) {
    console.error('Content structuring error:', error);

    // Handle timeout errors specifically
    if (error instanceof Error && (error.message.includes('timeout') || error.message.includes('TIMEOUT'))) {
      return NextResponse.json({
        code: 'TIMEOUT_ERROR',
        message: 'Content structuring took too long. Using original content.',
        fallbackTranscript: contentToStructure,
      }, { status: 408 });
    }

    // Handle OpenAI specific errors
    if (error instanceof Error && error.message.includes('OpenAI')) {
      return NextResponse.json({
        code: 'AI_SERVICE_ERROR',
        message: 'AI service is currently busy. Using original content.',
        fallbackTranscript: contentToStructure,
      }, { status: 503 });
    }

    return NextResponse.json({
      code: 'INTERNAL_ERROR',
      message: error instanceof Error ? error.message : 'Failed to structure content',
      fallbackTranscript: contentToStructure,
    }, { status: 500 });
  }
}
