# LLM Methods Advisory - Reframing for CDP-6 Compliance

**Date:** 4 December 2025  
**Issue:** Risk of assessor viewing LLM advisory as out-of-scope skills training
**Solution:** Tighten focus to information management aspects

---

## The Problem

### Original Phrasing (❌ Could Be Misinterpreted):

> "LLM training advisory teaches founder and Ting practical skills in NZ-LLM fine-tuning, evaluation frameworks, architectural paradigm comparison, and domain adaptation techniques. Knowledge directly transferable to future clinical AI projects."

**Assessor might think:** 
- "This is training them to DO R&D work (fine-tuning LLMs), not training them to MANAGE R&D information"
- "Skills training" instead of "information management capability"
- Out of scope for CDP-6: R&D Information Management

---

## The Solution

### Revised Phrasing (✅ Clearly CDP-6):

> "LLM methods advisory for founder and Ting focused on designing experiments, standardised evaluation frameworks, and architectural comparisons that integrate with our experiment tracking, model registry, and dataset lineage systems. Ensures clinical AI research outputs are consistently documented, comparable across projects, and properly archived for future reference."

**Assessor now sees:**
- ✅ Focus on documentation methodology, not model training
- ✅ Integration with experiment tracking systems (clearly CDP-6)
- ✅ Standardised frameworks for comparability
- ✅ Knowledge capture and archival (information management)
- ✅ Systematic documentation, not ad-hoc skills

---

## Key Changes Throughout Documents

### 1. Activity Title
- ❌ "LLM Training & Fine-Tuning Technical Advisory"
- ✅ "LLM Methods Advisory for R&D Information Management"

### 2. Focus Areas
**Before (skill-focused):**
- NZ-LLM training strategy
- Fine-tuning framework configuration (LoRA, QLoRA)
- Domain adaptation best practices
- Training pipeline setup

**After (documentation-focused):**
- Experiment design methodology for architectural comparison
- Standardised evaluation framework integrated with tracking system
- Architecture comparison methodology and results documentation
- Model checkpoint versioning and metadata standards
- Research results archival and knowledge capture

### 3. Deliverables
**Before (R&D outputs):**
- Training pipeline setup
- NZ-LLM fine-tuning playbook
- Domain adaptation strategies

**After (information management outputs):**
- Standardised evaluation framework integrated with tracking system
- Experiment design templates for architectural comparison
- Model registry metadata standards and versioning protocols
- Research documentation workflows and templates

### 4. Provider Selection Criteria
**Before:**
- "Proven LLM fine-tuning experience"
- "Clinical LLM track record"

**After:**
- "ML research infrastructure experience"
- "LLM experiment documentation and comparison methodologies"
- "MLOps and research information management expertise"
- "Focus on systematic documentation, not just model performance"

---

## Why This Matters

### CDP-6 Scope: R&D Information Management

**In scope:**
- ✅ Experiment tracking systems
- ✅ Model registries and versioning
- ✅ Dataset lineage documentation
- ✅ Evaluation frameworks
- ✅ Research documentation workflows
- ✅ Knowledge capture and archival

**Out of scope:**
- ❌ Training to build models (that's R&D work, not info management)
- ❌ Learning domain-specific techniques (that's technical capability, not documentation)
- ❌ Skills to fine-tune LLMs (that's doing R&D, not managing R&D information)

---

## The Distinction

| ❌ Skills Training (Out of Scope) | ✅ Information Management (CDP-6) |
|-----------------------------------|----------------------------------|
| "Learn how to fine-tune LLMs" | "Learn how to document LLM experiments systematically" |
| "Master domain adaptation techniques" | "Design evaluation frameworks for comparing approaches" |
| "Build training pipelines" | "Establish metadata standards for model versioning" |
| "Optimize model performance" | "Create templates for architectural comparison documentation" |
| Focus: Building models | Focus: Documenting research process |

---

## How We Frame It Now

**Key phrasing:**
- "Experiment design methodology"
- "Standardised evaluation frameworks"
- "Architectural comparison methodologies"
- "Model registry metadata standards"
- "Research documentation workflows"
- "Knowledge capture frameworks"
- "Integration with experiment tracking systems"

**Every activity ties back to:** How do we systematically document, track, compare, and archive our architectural investigation so knowledge is transferable to future projects?

---

## Documents Updated

1. ✅ `capability-development-portal-answer.md` - Portal answer reframed
2. ✅ `capability-development-evidence-pack.md` - Complete section rewrite
3. ✅ `forge-application-narrative.md` - CapDev section updated
4. ✅ `PROJECT_SUMMARY.md` - Summary section updated
5. ✅ `CAPDEV-RESTRUCTURE-SUMMARY.md` - Rationale updated

---

## Assessor Will Now See

**Before (Red Flag):**
> "You're training the founder to fine-tune LLMs? That's not information management, that's technical R&D work. Out of scope for CDP-6."

**After (Green Flag):**
> "You're building capability to systematically document and compare LLM experiments using standardised evaluation frameworks integrated with your tracking system. That's exactly what CDP-6 is for - managing R&D information for reproducibility and knowledge transfer."

---

**Status:** All documents updated with proper CDP-6 framing

**Risk Level:** Reduced from MEDIUM to LOW

**Credit:** Flagged by user's Perplexity AI query - excellent catch!
